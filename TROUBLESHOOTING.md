# æ•…éšœæ’æŸ¥æŠ¥å‘Š

## å®éªŒå¤±è´¥ä¿¡æ¯

**é€€å‡ºä»£ç **: 137
**å«ä¹‰**: SIGKILL (ä¿¡å· 9) - è¿›ç¨‹è¢«å¼ºåˆ¶ç»ˆæ­¢
**æ—¶é—´**: 2025-12-31 12:03 - 12:32 (çº¦29åˆ†é’Ÿå)

## å¤±è´¥ä½ç½®

```
Processing reducer: PCA
--- Dimensions: 10 ---
Reduced to shape: (262544, 10)
Explained variance ratio: 0.9935
Class separation ratio: 0.0056
Generating 2D visualization...
Saved plot: PCA_10_2d.png

Training SVM... â† å¡åœ¨è¿™é‡Œ
```

## é€€å‡ºä»£ç  137 çš„å¯èƒ½åŸå› 

### 1. æ‰‹åŠ¨ç»ˆæ­¢ (æœ€å¯èƒ½)
- ä½¿ç”¨ `pkill -9` å¼ºåˆ¶ç»ˆæ­¢
- æˆ–ç”¨æˆ·æŒ‰ Ctrl+C åç³»ç»Ÿå‘é€ SIGKILL
- **æœ¬æ¬¡æƒ…å†µ**: âœ… æˆ‘ä»¬æ‰‹åŠ¨æ‰§è¡Œäº† `pkill -9 -f run_experiments_torch`

### 2. å†…å­˜ä¸è¶³ (OOM Killer)
- ç³»ç»Ÿå†…å­˜è€—å°½æ—¶ï¼ŒLinux OOM Killer ä¼šæ€æ‰å ç”¨å¤§çš„è¿›ç¨‹
- å…¸å‹ç‰¹å¾ï¼šdmesg ä¼šæœ‰ "Out of memory" æˆ– "Killed process" æ—¥å¿—
- **æœ¬æ¬¡æƒ…å†µ**: âŒ æ— æ˜æ˜¾å†…å­˜ä¸è¶³æ—¥å¿—ï¼ˆä½†æ— æƒé™æŸ¥çœ‹å®Œæ•´ dmesgï¼‰

### 3. ç³»ç»Ÿèµ„æºé™åˆ¶
- ulimit é™åˆ¶ï¼ˆå†…å­˜ã€CPUæ—¶é—´ã€è¿›ç¨‹æ•°ï¼‰
- cgroup é™åˆ¶
- **æœ¬æ¬¡æƒ…å†µ**: â“ æœªæ£€æŸ¥

## æ€§èƒ½é—®é¢˜åˆ†æ

### SVM ç½‘æ ¼æœç´¢ä¸ºä½•å¦‚æ­¤æ…¢ï¼Ÿ

**æ•°æ®è§„æ¨¡**:
- è®­ç»ƒæ ·æœ¬: 262,544 æ¡
- ç‰¹å¾ç»´åº¦: 10 (PCA é™ç»´å)

**ç½‘æ ¼æœç´¢é…ç½®**:
```python
{
    "C": [0.1, 1, 10],           # 3 ä¸ªå€¼
    "kernel": ["linear", "rbf"],  # 2 ä¸ªå€¼
    "gamma": ["scale", "auto"]    # 2 ä¸ªå€¼ (ä»… rbf kernel)
}
```

**å®é™…ç»„åˆ**:
- linear kernel: C=3 ç§ â†’ 3 ç»„
- rbf kernel: C=3 ç§ Ã— gamma=2 ç§ â†’ 6 ç»„
- **æ€»è®¡**: 9 ç»„å‚æ•°ç»„åˆ

**äº¤å‰éªŒè¯**:
- 3-fold CV â†’ æ¯ç»„å‚æ•°è®­ç»ƒ 3 æ¬¡
- **æ€»è®¡**: 9 Ã— 3 = 27 æ¬¡ SVM è®­ç»ƒ

**CPU ä½¿ç”¨æƒ…å†µ**:
- è§‚å¯Ÿåˆ° 5 ä¸ª Python è¿›ç¨‹ï¼Œæ¯ä¸ª 100% CPU
- è¯´æ˜ `n_jobs=-1` å¤šæ ¸å¹¶è¡Œç”Ÿæ•ˆ
- ä½†å³ä½¿å¤šæ ¸ï¼Œ26ä¸‡æ ·æœ¬çš„ SVM ä»ç„¶å¾ˆæ…¢

**æ—¶é—´ä¼°ç®—**:
- å•ä¸ªç½‘æ ¼æœç´¢: 30+ åˆ†é’Ÿ
- 27 ç»„å®éªŒ Ã— 30 åˆ†é’Ÿ = **13.5+ å°æ—¶** ğŸ˜±

### ä¸ºä»€ä¹ˆ GPU åˆ©ç”¨ç‡ä½ï¼Ÿ

**è§‚å¯Ÿ**:
- GPU ä½¿ç”¨ç‡: 7-9%
- GPU æ˜¾å­˜: 2GB

**åŸå› **:
1. **PCA é™ç»´**: ä½¿ç”¨ PyTorch GPU âœ… (å·²å®Œæˆï¼Œå¾ˆå¿«)
2. **SVM è®­ç»ƒ**: ä½¿ç”¨ scikit-learn (çº¯ CPU) âŒ
   - scikit-learn çš„ SVM ä¸æ”¯æŒ GPU
   - å³ä½¿ `n_jobs=-1` ä½¿ç”¨å¤šæ ¸ï¼Œå¤§æ•°æ®é›†ä»ç„¶æ…¢
3. **Random Forest**: scikit-learn (çº¯ CPU)
4. **Logistic Regression**: PyTorch GPU âœ… (è¿˜æ²¡è¿è¡Œåˆ°)

**ç»“è®º**: GPU ä¸»è¦ç”¨äºé™ç»´é˜¶æ®µï¼Œåˆ†ç±»å™¨é˜¶æ®µå¤§éƒ¨åˆ†åœ¨ CPU ä¸Šã€‚

## å·²éªŒè¯çš„æ­£ç¡®éƒ¨åˆ†

âœ… **ç¯å¢ƒé…ç½®**:
- GPU è¯†åˆ«æ­£ç¡® (RTX 4060, CUDA 12.9)
- PyTorch GPU å¯ç”¨
- æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ

âœ… **æ•°æ®å¤„ç†**:
- æˆåŠŸåŠ è½½ 328,181 æ ·æœ¬
- é¢„å¤„ç†æ­£ç¡®ï¼ˆæ—  NaN/Infï¼‰
- ç±»åˆ«è¯†åˆ«æ­£ç¡®ï¼ˆ2 ç±»: Benign, DDoSï¼‰
- æ•°æ®åˆ’åˆ†æ­£ç¡®ï¼ˆ80/20 split, stratifiedï¼‰

âœ… **é™ç»´å®ç°**:
- PCA 10 ç»´æˆåŠŸ
- è§£é‡Šæ–¹å·®æ¯”: 99.35% (éå¸¸å¥½)
- ç±»é—´åˆ†ç¦»åº¦è®¡ç®—æ­£ç¡®
- å¯è§†åŒ–ç”ŸæˆæˆåŠŸ

âœ… **ä»£ç é€»è¾‘**:
- æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ
- PyTorch é™ç»´å™¨å·¥ä½œæ­£å¸¸
- æµç¨‹è®¾è®¡åˆç†

## æ ¹æœ¬é—®é¢˜

**æ ¸å¿ƒç“¶é¢ˆ**: scikit-learn çš„ SVM åœ¨å¤§æ•°æ®é›†ä¸Šçš„ç½‘æ ¼æœç´¢è¿‡æ…¢

**ä¸æ˜¯é—®é¢˜**:
- âŒ ä¸æ˜¯ä»£ç é”™è¯¯
- âŒ ä¸æ˜¯ GPU é…ç½®é—®é¢˜
- âŒ ä¸æ˜¯å†…å­˜æ³„æ¼
- âœ… æ˜¯ç®—æ³•å¤æ‚åº¦ + æ•°æ®è§„æ¨¡å¯¼è‡´çš„å¿…ç„¶ç»“æœ

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ A: æ•°æ®é‡‡æ ·ï¼ˆæ¨è â­ï¼‰

**ä¿®æ”¹ç‚¹**: åœ¨æ•°æ®åŠ è½½åæ·»åŠ é‡‡æ ·
```python
# åœ¨ train_test_split ä¹‹å‰
if len(df) > 100000:
    df = df.sample(n=100000, random_state=RANDOM_SEED, stratify=df[LABEL_COL])
```

**æ•ˆæœ**:
- æ ·æœ¬æ•°: 262,544 â†’ 100,000 (å‡å°‘ 62%)
- æ—¶é—´: 30åˆ†é’Ÿ â†’ 10-12 åˆ†é’Ÿ (é¢„è®¡)
- æ€»æ—¶é—´: 13å°æ—¶ â†’ 4-5 å°æ—¶ â†’ **ä»ç„¶å¤ªæ…¢**

**è¿›ä¸€æ­¥ä¼˜åŒ–**: é‡‡æ ·åˆ° 50,000
- æ—¶é—´: 30åˆ†é’Ÿ â†’ 5-6 åˆ†é’Ÿ
- æ€»æ—¶é—´: 13å°æ—¶ â†’ 2-3 å°æ—¶
- **å¯æ¥å—**

### æ–¹æ¡ˆ B: ç®€åŒ–ç½‘æ ¼æœç´¢

**ä¿®æ”¹ç‚¹**: å‡å°‘å‚æ•°ç»„åˆ
```python
"SVM": {
    "C": [1, 10],              # 3â†’2
    "kernel": ["rbf"],         # 2â†’1 (åªä¿ç•™ rbf)
    "gamma": ["scale"],        # 2â†’1
}
# 9 ç»„ â†’ 2 ç»„, æ—¶é—´å‡å°‘ 78%
```

**æ•ˆæœ**:
- å•ä¸ªç½‘æ ¼æœç´¢: 30åˆ†é’Ÿ â†’ 7åˆ†é’Ÿ
- æ€»æ—¶é—´: 13å°æ—¶ â†’ 3å°æ—¶
- **å¯æ¥å—ä½†ä»è¾ƒé•¿**

### æ–¹æ¡ˆ C: åŒç®¡é½ä¸‹ï¼ˆæœ€æ¨è â­â­â­ï¼‰

**ç»„åˆ**: é‡‡æ · + ç®€åŒ–ç½‘æ ¼
- é‡‡æ ·åˆ° 50,000
- ç®€åŒ– SVM å‚æ•°åˆ° 2 ç»„
- ç®€åŒ– RF å‚æ•°

**æ•ˆæœ**:
- å•ä¸ªç½‘æ ¼æœç´¢: 30åˆ†é’Ÿ â†’ 2-3 åˆ†é’Ÿ
- æ€»æ—¶é—´: 13å°æ—¶ â†’ **30-60 åˆ†é’Ÿ**
- **é«˜æ€§ä»·æ¯”**

### æ–¹æ¡ˆ D: ä½¿ç”¨ GPU SVM

**å·¥å…·**: thundersvm æˆ– cuML
```bash
pixi add thundersvm
# æˆ–
pixi add cuml
```

**ä¼˜ç‚¹**: å……åˆ†åˆ©ç”¨ GPU
**ç¼ºç‚¹**:
- éœ€è¦é¢å¤–å®‰è£…
- å¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜
- cuML ä¾èµ–è¾ƒé‡

### æ–¹æ¡ˆ E: å‡å°‘å®éªŒç»„åˆæ•°

**ä¿®æ”¹**: åªæµ‹è¯•å…³é”®ç»„åˆ
- é™ç»´: PCA, LDA (å»æ‰ t-SNEï¼Œå®ƒæœ€æ…¢)
- ç»´åº¦: 10, 20 (å»æ‰ 15)
- åˆ†ç±»å™¨: SVM, RandomForest, LogisticRegression

**ç»„åˆ**: 2 Ã— 2 Ã— 3 = 12 ç»„ (åŸæ¥ 27 ç»„)
- æ—¶é—´å‡å°‘ 55%

## æ¨èæ–¹æ¡ˆ

**æœ€ä½³æ–¹æ¡ˆ**: **C + E ç»„åˆ**
1. æ•°æ®é‡‡æ ·åˆ° 50,000
2. ç®€åŒ– SVM ç½‘æ ¼æœç´¢
3. å»æ‰ t-SNE (æˆ–å•ç‹¬è·‘)
4. å‡å°‘ç»´åº¦æµ‹è¯•ç‚¹

**é¢„è®¡æ•ˆæœ**:
- æ€»æ—¶é—´: **15-30 åˆ†é’Ÿ**
- ç»“æœè´¨é‡: **è‰¯å¥½** (50k æ ·æœ¬è¶³å¤Ÿ)
- GPU åˆ©ç”¨: **ä¸­ç­‰** (é™ç»´é˜¶æ®µ)

## å®æ–½å»ºè®®

1. **ç«‹å³å¯è¡Œ**: å…ˆç”¨æ–¹æ¡ˆ C è·‘ä¸€é
2. **åç»­ä¼˜åŒ–**: å¦‚æœè¿˜æƒ³ç”¨å®Œæ•´æ•°æ®ï¼Œè€ƒè™‘æ–¹æ¡ˆ D (GPU SVM)
3. **å­¦ä¹ ä»·å€¼**: å½“å‰ä»£ç å·²ç»å±•ç¤ºäº† PyTorch GPU åŠ é€Ÿçš„èƒ½åŠ›
4. **æ—¶é—´ç®¡ç†**: è¯¾ç¨‹ä½œä¸šåº”ä¼˜å…ˆä¿è¯å®Œæˆï¼Œè€Œéè¿½æ±‚å®Œç¾

## ä»£ç ä¿®æ”¹æ¸…å•

### 1. æ·»åŠ æ•°æ®é‡‡æ ·
```python
# run_experiments.py, line ~85
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y
)

# æ·»åŠ é‡‡æ ·
if len(X_train) > 50000:
    sample_idx = np.random.RandomState(RANDOM_SEED).choice(
        len(X_train), size=50000, replace=False
    )
    X_train = X_train[sample_idx]
    y_train = y_train[sample_idx]
    print(f"Sampled training set to {len(X_train)} samples")
```

### 2. ç®€åŒ–ç½‘æ ¼æœç´¢
```python
# run_experiments.py, line ~94-115
classifiers = {
    "SVM": {
        "type": "sklearn",
        "model": SVC(),
        "param_grid": {
            "C": [1, 10],           # ç®€åŒ–
            "kernel": ["rbf"],       # åªä¿ç•™ rbf
            "gamma": ["scale"],      # åªä¿ç•™ scale
        },
    },
    "RandomForest": {
        "type": "sklearn",
        "model": RandomForestClassifier(random_state=RANDOM_SEED),
        "param_grid": {
            "n_estimators": [200],      # å›ºå®š
            "max_depth": [None, 20],    # ç®€åŒ–
            "min_samples_split": [2],   # å›ºå®š
        },
    },
    "LogisticRegression": {
        "type": "torch",
        "param_grid": {
            "C": [1, 10],           # ç®€åŒ–
            "max_iter": [1000],     # å›ºå®š
        },
    },
}
```

### 3. å‡å°‘å®éªŒç»„åˆ
```python
# run_experiments.py, line ~130
reducers = ["PCA", "LDA"]  # å»æ‰ t-SNE
dims = [10, 20]            # å»æ‰ 15
```

## æ€»ç»“

**é—®é¢˜**: SVM ç½‘æ ¼æœç´¢åœ¨å¤§æ•°æ®é›†ä¸Šææ…¢
**åŸå› **: ç®—æ³•å¤æ‚åº¦ O(nÂ²~nÂ³) + 26ä¸‡æ ·æœ¬
**è§£å†³**: é‡‡æ · + ç®€åŒ–å‚æ•° + å‡å°‘ç»„åˆ
**é¢„æœŸ**: 30-60 åˆ†é’Ÿå®Œæˆå…¨éƒ¨å®éªŒ
**ä»£ä»·**: ç»“æœç²¾åº¦ç•¥æœ‰ä¸‹é™ï¼Œä½†åœ¨å¯æ¥å—èŒƒå›´å†…

**ä¸‹ä¸€æ­¥**: ä¿®æ”¹ä»£ç å¹¶é‡æ–°è¿è¡Œï¼Ÿ
