# 实验记录

## 实验时间
- **开始时间**: 2025-12-31 12:03
- **终止时间**: 2025-12-31 12:32
- **运行时长**: 约 29 分钟

## 实验配置

### 硬件环境
- **GPU**: NVIDIA GeForce RTX 4060 Laptop GPU
- **CUDA**: 12.9
- **CPU**: Intel i7-12650H (16 核心)
- **内存**: 充足

### 软件环境
- **Python**: 3.11
- **PyTorch**: 2.9 (GPU 版本)
- **Scikit-learn**: 最新稳定版
- **其他**: pandas, numpy, matplotlib, scienceplots

### 数据集
- **名称**: CSE-CIC-IDS2018 (Thursday-01-03-2018)
- **原始样本数**: 328,181
- **类别数**: 2 (Benign, DDoS)
- **训练集**: 262,544 样本 (80%)
- **测试集**: 65,637 样本 (20%)
- **特征数**: 30 个核心流量特征

### 实验设计
- **降维方法**: PCA, LDA, t-SNE
- **降维维度**: 10, 15, 20
- **分类器**: SVM, Random Forest, Logistic Regression
- **总实验组合**: 3 × 3 × 3 = 27 组

## 实验进展

### 已完成部分
1. ✅ 数据加载与预处理成功
2. ✅ PCA 10 维降维完成
   - 解释方差比: 0.9935 (99.35%)
   - 类间分离度: 0.0056
3. ✅ 生成可视化图: `PCA_10_2d.png`

### 遇到的问题

#### 性能瓶颈：SVM 网格搜索过慢
**问题描述**:
- 在 PCA-10维 + SVM 网格搜索阶段卡住
- 运行 29 分钟仍未完成第一个分类器训练
- 5 个 Python 工作进程 CPU 使用率 100%，说明在努力计算

**原因分析**:
1. **数据量大**: 26 万训练样本对于 SVM 来说计算量巨大
2. **网格搜索参数多**:
   - C: [0.1, 1, 10] = 3 个值
   - kernel: [linear, rbf] = 2 个值
   - gamma: [scale, auto] = 2 个值
   - 总组合: 3 × 2 × 2 = 12 组（rbf kernel 才用 gamma，实际约 9 组有效组合）
3. **交叉验证**: 3 折 CV，每组参数训练 3 次
4. **总计**: 约 27-36 次 SVM 训练，每次都在 26 万样本上

**时间估算**:
- 单个网格搜索: 30+ 分钟
- 27 组实验: 预计 10-20 小时（不可接受）

## GPU 利用情况

### 观察到的现象
- GPU 使用率: 7-9% (较低)
- GPU 显存: 2GB (较少)
- CPU 使用率: 多核心接近 100% (高)

### 原因
- **降维部分**: PCA/LDA/t-SNE 使用 PyTorch GPU 加速 ✅
- **分类器部分**:
  - SVM 和 Random Forest 使用 scikit-learn (纯 CPU，多核并行)
  - 只有 Logistic Regression 使用 PyTorch GPU 加速

scikit-learn 的 SVM 实现不支持 GPU，即使使用 `n_jobs=-1` 多核并行，在大数据集上仍然很慢。

## 优化建议

### 方案 1: 数据采样（推荐）
- 从 26 万样本采样至 5-10 万
- 保持类别平衡（分层采样）
- **优点**: 速度提升 3-5 倍，结果仍可信
- **预计时间**: 15-30 分钟完成全部实验

### 方案 2: 简化网格搜索
- 减少参数组合：
  - SVM: C=[1, 10], kernel=[rbf] → 2 组
  - Random Forest: 减少树的数量测试点
- **优点**: 速度提升 2-3 倍
- **预计时间**: 1-2 小时

### 方案 3: 双管齐下
- 采样 + 简化网格搜索
- **优点**: 最快
- **预计时间**: 10-20 分钟
- **缺点**: 结果精度略有下降

### 方案 4: 使用 GPU 加速的 SVM 替代
- 考虑使用 cuML 的 SVM 实现（支持 GPU）
- 或使用 thundersvm（专门的 GPU SVM 库）
- **优点**: 充分利用 GPU，速度提升显著
- **缺点**: 需要额外安装和调试

## 已生成文件

### 代码模块
- `code/torch_reducers.py` - PyTorch GPU 降维实现
- `code/torch_classifiers.py` - PyTorch GPU 分类器实现
- `code/run_experiments_torch.py` - 完整实验流程
- `code/preprocess.py` - 数据预处理
- `code/metrics.py` - 评估指标
- `code/plots.py` - 可视化（IEEE 风格）
- `code/config.py` - 配置文件

### 实验结果
- `figures/PCA_10_2d.png` - PCA 10 维可视化
- `experiment_log.txt` - 实验运行日志

## 下一步行动

1. **选择优化方案** - 建议采用方案 1（数据采样）
2. **修改实验脚本** - 添加采样逻辑
3. **重新运行实验** - 预计 15-30 分钟完成
4. **生成完整结果** - 填充 results.md, report.md, rules.md
5. **文档整理** - 更新 README.md 说明

## 经验教训

1. **数据规模评估**: 26 万样本对于 SVM 网格搜索来说过大，应该提前采样
2. **时间预算**: 应该先用小规模数据测试流程，估算时间后再全量运行
3. **GPU 利用**: scikit-learn 的传统算法不支持 GPU，PyTorch 实现的价值主要在降维阶段
4. **渐进式开发**: 可以先跑 1-2 组验证流程，再扩展到全部 27 组
5. **进度可视化**: 应该在代码中添加进度条（tqdm）和中间结果保存

## 备注

本次实验虽未完成全部流程，但验证了：
- GPU 环境配置正确
- 数据预处理流程正确
- PyTorch 降维实现正确（PCA 解释方差比达 99.35%）
- 代码逻辑无误，只是时间问题

下次实验将采用优化方案，确保在合理时间内完成。
