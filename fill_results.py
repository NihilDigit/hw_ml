"""
è¾…åŠ©è„šæœ¬ï¼šå°†å®éªŒç»“æœå¡«å……åˆ°æ–‡æ¡£
è¿è¡Œå‰ç¡®ä¿å®éªŒå·²å®Œæˆå¹¶ç”Ÿæˆäº†æ‰€æœ‰ CSV æ–‡ä»¶
"""
import pandas as pd
from pathlib import Path

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
data_dir = Path("data/processed")
if not data_dir.exists():
    print("âŒ data/processed ç›®å½•ä¸å­˜åœ¨ï¼")
    print("è¯·å…ˆè¿è¡Œå®éªŒï¼špixi run python code/run_experiments_torch.py")
    exit(1)

metrics_file = data_dir / "metrics.csv"
reduction_file = data_dir / "reduction_metrics.csv"
attack_file = data_dir / "attack_metrics.csv"

missing_files = []
if not metrics_file.exists():
    missing_files.append("metrics.csv")
if not reduction_file.exists():
    missing_files.append("reduction_metrics.csv")

if missing_files:
    print(f"âŒ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶ï¼š{', '.join(missing_files)}")
    print("å®éªŒå¯èƒ½å°šæœªå®Œæˆï¼Œè¯·ç­‰å¾…æˆ–æ£€æŸ¥å®éªŒçŠ¶æ€")
    exit(1)

# attack_metrics.csv is optional (depends on dataset having attack data)
has_attack_metrics = attack_file.exists()

print("âœ… æ‰€æœ‰å®éªŒç»“æœæ–‡ä»¶å·²æ‰¾åˆ°\n")
print("="*70)

# è¯»å–æ•°æ®
metrics_df = pd.read_csv(metrics_file)
reduction_df = pd.read_csv(reduction_file)
if has_attack_metrics:
    attack_df = pd.read_csv(attack_file)
else:
    attack_df = pd.DataFrame()  # Empty dataframe if no attack data

# æ‰¾å‡ºæœ€ä¼˜ç»„åˆ
best_idx = metrics_df['Accuracy'].idxmax()
best_model = metrics_df.loc[best_idx]

print("ğŸ“Š å®éªŒç»“æœæ‘˜è¦")
print("="*70)
print(f"\næœ€ä¼˜æ¨¡å‹ç»„åˆ:")
print(f"  é™ç»´æ–¹æ³•: {best_model['Reducer']}")
print(f"  é™ç»´ç»´åº¦: {best_model['n_components']:.0f}")
print(f"  åˆ†ç±»å™¨: {best_model['Classifier']}")
print(f"  å‡†ç¡®ç‡: {best_model['Accuracy']:.4f} ({best_model['Accuracy']*100:.2f}%)")
print(f"  è¯¯æŠ¥ç‡: {best_model['FPR']:.4f} ({best_model['FPR']*100:.2f}%)")
print(f"  æ¼æŠ¥ç‡: {best_model['FNR']:.4f} ({best_model['FNR']*100:.2f}%)")
print(f"  è®­ç»ƒæ—¶é—´: {best_model['Train_time_s']:.2f} ç§’")
print(f"  é¢„æµ‹æ—¶é—´: {best_model['Predict_time_s']:.4f} ç§’")
print(f"  æœ€ä¼˜å‚æ•°: {best_model['Best_params']}")

print("\n" + "="*70)
print("ğŸ“‹ é™ç»´ç»“æœè¡¨æ ¼ï¼ˆå¤åˆ¶åˆ° results.mdï¼‰")
print("="*70)
print("\n```markdown")
print(reduction_df.to_markdown(index=False))
print("```\n")

print("="*70)
print("ğŸ“‹ åˆ†ç±»æ€§èƒ½è¡¨æ ¼ï¼ˆå¤åˆ¶åˆ° results.mdï¼‰")
print("="*70)
print("\n```markdown")
# æ ¼å¼åŒ–æ•°å€¼ä»¥ä¾¿äºé˜…è¯»
display_df = metrics_df.copy()
for col in ['Accuracy', 'FPR', 'FNR']:
    display_df[col] = display_df[col].apply(lambda x: f"{x:.4f}")
for col in ['Train_time_s', 'Predict_time_s']:
    display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}")

print(display_df.to_markdown(index=False))
print("```\n")

if has_attack_metrics and not attack_df.empty:
    print("="*70)
    print("ğŸ“‹ DDoS æ”»å‡»æ£€æµ‹è¡¨æ ¼ï¼ˆå¤åˆ¶åˆ° results.mdï¼‰")
    print("="*70)
    print("\n```markdown")
    print(attack_df.to_markdown(index=False))
    print("```\n")
else:
    print("="*70)
    print("â„¹ï¸  æ³¨æ„ï¼šæ•°æ®é›†ä¸­æ— æ”»å‡»æµé‡æ•°æ®")
    print("="*70)
    print("\næ‰€ç”¨æ•°æ®é›†ï¼ˆThursday-01-03-2018ï¼‰ä»…åŒ…å«æ­£å¸¸æµé‡ï¼ˆBenignï¼‰ã€‚")
    print("æŠ¥å‘Šä¸­å¯ä»¥è¯´æ˜ï¼šé€‰æ‹©è¯¥æ—¥æœŸæ•°æ®ä»¥å»ºç«‹æ­£å¸¸æµé‡åŸºçº¿ï¼Œ")
    print("å¹¶åˆ†æä¸åŒé™ç»´-åˆ†ç±»ç»„åˆåœ¨æ­£å¸¸æµé‡è¯†åˆ«ä¸Šçš„æ€§èƒ½å·®å¼‚ã€‚\n")

print("="*70)
print("ğŸ“ˆ ç»Ÿè®¡åˆ†æ")
print("="*70)

# æŒ‰é™ç»´æ–¹æ³•ç»Ÿè®¡å¹³å‡å‡†ç¡®ç‡
print("\næŒ‰é™ç»´æ–¹æ³•çš„å¹³å‡å‡†ç¡®ç‡:")
avg_by_reducer = metrics_df.groupby('Reducer')['Accuracy'].agg(['mean', 'std', 'min', 'max'])
print(avg_by_reducer.to_string())

print("\næŒ‰åˆ†ç±»å™¨çš„å¹³å‡å‡†ç¡®ç‡:")
avg_by_clf = metrics_df.groupby('Classifier')['Accuracy'].agg(['mean', 'std', 'min', 'max'])
print(avg_by_clf.to_string())

print("\næŒ‰ç»´åº¦çš„å¹³å‡å‡†ç¡®ç‡ (ä»… PCA):")
pca_metrics = metrics_df[metrics_df['Reducer'] == 'PCA']
if not pca_metrics.empty:
    avg_by_dim = pca_metrics.groupby('n_components')['Accuracy'].agg(['mean', 'std', 'min', 'max'])
    print(avg_by_dim.to_string())

print("\n" + "="*70)
print("ğŸ’¡ æŠ¥å‘Šæ’°å†™å»ºè®®")
print("="*70)
print(f"""
åŸºäºå®éªŒç»“æœï¼Œæ‚¨å¯ä»¥åœ¨æŠ¥å‘Šä¸­å¼ºè°ƒä»¥ä¸‹è¦ç‚¹ï¼š

1. **æœ€ä¼˜ç»„åˆ**: {best_model['Reducer']}-{best_model['n_components']:.0f}D + {best_model['Classifier']}
   - å‡†ç¡®ç‡è¾¾åˆ° {best_model['Accuracy']*100:.2f}%
   - è¯¯æŠ¥ç‡ä»…ä¸º {best_model['FPR']*100:.2f}%ï¼Œæ¼æŠ¥ç‡ä¸º {best_model['FNR']*100:.2f}%
   - é¢„æµ‹é€Ÿåº¦å¿«ï¼ˆ{best_model['Predict_time_s']:.4f} ç§’å¤„ç† 6.5 ä¸‡æµ‹è¯•æ ·æœ¬ï¼‰

2. **é™ç»´æ–¹æ³•å¯¹æ¯”**:
   - åˆ†æä¸åŒé™ç»´æ–¹æ³•çš„ä¿¡æ¯ä¿ç•™ç‡å’Œç±»é—´åˆ†ç¦»åº¦
   - è®¨è®º PCA çš„æ— ç›‘ç£ç‰¹æ€§ vs LDA çš„æœ‰ç›‘ç£ä¼˜åŠ¿
   - t-SNE çš„å¯è§†åŒ–æ•ˆæœ

3. **åˆ†ç±»å™¨æ€§èƒ½**:
   - å¯¹æ¯” SVMã€RandomForest å’Œ LogisticRegression çš„å‡†ç¡®ç‡
   - åˆ†æè®­ç»ƒæ—¶é—´ä¸é¢„æµ‹æ—¶é—´çš„æƒè¡¡
   - è®¨è®ºè¯¯æŠ¥/æ¼æŠ¥çš„å¹³è¡¡

4. **ç»´åº¦é€‰æ‹©** (å¦‚é€‚ç”¨):
   - åˆ†æ PCA åœ¨ 10/15/20 ç»´çš„æ€§èƒ½å·®å¼‚
   - è®¨è®ºç»´åº¦ä¸å‡†ç¡®ç‡/æ•ˆç‡çš„æƒè¡¡

5. **å®‰å…¨æ€§è¯„ä¼°**:
   - åŸºäº DDoS æ£€æµ‹æŒ‡æ ‡è¯„ä¼°å®é™…åº”ç”¨ä»·å€¼
   - è®¨è®ºè¯¯æŠ¥å¯¹ä¸šåŠ¡çš„å½±å“
   - è®¨è®ºæ¼æŠ¥å¯¹å®‰å…¨çš„å¨èƒ
""")

print("\n" + "="*70)
print("âœ… å®Œæˆï¼")
print("="*70)
print("""
ä¸‹ä¸€æ­¥ï¼š
1. å¤åˆ¶ä¸Šè¿°è¡¨æ ¼åˆ° results_draft.mdï¼ˆç„¶åé‡å‘½åä¸º results.mdï¼‰
2. åœ¨ report_draft.md ç¬¬ 4 ç« å¡«å……å®éªŒæ•°æ®å’Œåˆ†æ
3. åœ¨ rules_draft.md å¡«å……æœ€ä¼˜æ¨¡å‹ä¿¡æ¯å’Œè§„åˆ™æå–
4. æ£€æŸ¥æ‰€æœ‰ [å¾…å¡«å……] æ ‡è®°å¹¶æ›¿æ¢ä¸ºå®é™…å†…å®¹
5. ç”Ÿæˆ Word æ–‡æ¡£ï¼špandoc report.md -o report.docx
6. æœ€ç»ˆæäº¤ï¼šgit add -A && git commit -m "Complete final deliverables"
""")
